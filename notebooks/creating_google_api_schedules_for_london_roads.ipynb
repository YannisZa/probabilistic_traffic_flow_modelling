{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "organizational-director",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import multiprocessing as mp\n",
    "import datetime as dt\n",
    "import scipy.linalg\n",
    "import scipy.stats\n",
    "import shapely.wkt \n",
    "import itertools\n",
    "import polyline\n",
    "import pytz\n",
    "import copy\n",
    "\n",
    "\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from collections import Counter\n",
    "from sklearn.neighbors import BallTree\n",
    "from shapely.geometry import Point,LineString\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-nirvana",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "moderate-respondent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import camera to roads dataframe\n",
    "cameras_to_roads_filenames = \"../data/output/misc/cameras_to_roads.csv\"\n",
    "cameras_to_roads = pd.read_csv(cameras_to_roads_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-anaheim",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "aerial-castle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only necessary columns\n",
    "cameras_to_roads = cameras_to_roads[['camera_id','road_id','road_geometry']]\n",
    "# Convert camera id from float to string\n",
    "cameras_to_roads['camera_id'] = cameras_to_roads.camera_id.astype('str')\n",
    "cameras_to_roads['road_id'] = cameras_to_roads.road_id.astype('str')\n",
    "# Remove duplicate rows (i.e. rows with same camera id and road id)\n",
    "cameras_to_roads = cameras_to_roads.drop_duplicates(subset=['camera_id','road_id'])\n",
    "# Convert string to geometry\n",
    "cameras_to_roads['road_geometry'] = cameras_to_roads['road_geometry'].apply(lambda x: shapely.wkt.loads(x))\n",
    "# Convert dataframe to geodataframe\n",
    "cameras_to_roads_gdf = gpd.GeoDataFrame(cameras_to_roads,geometry='road_geometry',crs=\"EPSG:4326\")\n",
    "# # Extract endpoints from road into tuple\n",
    "# cameras_to_roads_gdf['Origin'] = cameras_to_roads_gdf.road_geometry.apply(lambda x: x.coords[0])\n",
    "# cameras_to_roads_gdf['Destination'] = cameras_to_roads_gdf.road_geometry.apply(lambda x: x.coords[-1])\n",
    "#Extract endpoints from road into columns\n",
    "cameras_to_roads_gdf[['OLon','OLat']] = cameras_to_roads_gdf.road_geometry.apply(lambda x: x.coords[0]).apply(pd.Series)\n",
    "cameras_to_roads_gdf[['DLon','DLat']] = cameras_to_roads_gdf.road_geometry.apply(lambda x: x.coords[-1]).apply(pd.Series)\n",
    "# Create dummy key for outer join\n",
    "cameras_to_roads_gdf['key'] = 0\n",
    "# Remove duplicate roads\n",
    "cameras_to_roads_gdf = cameras_to_roads_gdf.drop_duplicates(subset=['road_id'])\n",
    "# Create roads closest to cameras geodataframe\n",
    "roads_closest_to_cameras = cameras_to_roads_gdf[['road_id','road_geometry','camera_id']]\n",
    "# Group camera ids by road ids\n",
    "roads_closest_to_cameras = cameras_to_roads_gdf.groupby(cameras_to_roads_gdf.road_id).agg({'camera_id':', '.join,'road_geometry':'first'}).reset_index()\n",
    "# Convert dataframe to geodataframe\n",
    "roads_closest_to_cameras = gpd.GeoDataFrame(roads_closest_to_cameras,geometry='road_geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "incoming-korea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of road requests from 2331 reduced to 244\n"
     ]
    }
   ],
   "source": [
    "# Decide on how many origins/destinations to group together into one polyline\n",
    "num_points = 10\n",
    "encoding_precision = 5\n",
    "\n",
    "# Encode origin and destination points using Googleâ€™s Encoded Polyline Algorithm\n",
    "cameras_to_roads_gdf['Oencoded'] = cameras_to_roads_gdf.road_geometry.apply(lambda x: ('enc:'+polyline.encode([x.coords[0][::-1]],encoding_precision)+\":\"))\n",
    "cameras_to_roads_gdf['Dencoded'] = cameras_to_roads_gdf.road_geometry.apply(lambda x: ('enc:'+polyline.encode([x.coords[-1][::-1]],encoding_precision)+\":\"))\n",
    "# Format string in coordinates\n",
    "cameras_to_roads_gdf['OLat'] = cameras_to_roads_gdf.OLat.apply(lambda x: '{0:.10f}'.format(x))\n",
    "cameras_to_roads_gdf['OLon'] = cameras_to_roads_gdf.OLon.apply(lambda x: '{0:.10f}'.format(x))\n",
    "cameras_to_roads_gdf['DLat'] = cameras_to_roads_gdf.DLat.apply(lambda x: '{0:.10f}'.format(x))\n",
    "cameras_to_roads_gdf['DLon'] = cameras_to_roads_gdf.DLon.apply(lambda x: '{0:.10f}'.format(x))\n",
    "# Convert coordinates to strings\n",
    "cameras_to_roads_gdf[['OLat_str','OLon_str']] = cameras_to_roads_gdf[['OLat','OLon']].astype('str')\n",
    "cameras_to_roads_gdf[['DLat_str','DLon_str']] = cameras_to_roads_gdf[['DLat','DLon']].astype('str')\n",
    "# Join columns and separate them by commas\n",
    "cameras_to_roads_gdf['Olatlon'] = cameras_to_roads_gdf[['OLat_str','OLon_str']].apply(lambda x: ','.join(x[x.notnull()]), axis = 1).astype('str')\n",
    "cameras_to_roads_gdf['Dlatlon'] = cameras_to_roads_gdf[['DLat_str','DLon_str']].apply(lambda x: ','.join(x[x.notnull()]), axis = 1).astype('str')\n",
    "\n",
    "if num_points > 1:\n",
    "    # Concatenate every num_points rows/roads into one\n",
    "    cameras_to_roads_gdf_grouped = cameras_to_roads_gdf.groupby(cameras_to_roads_gdf.index // num_points).agg({\n",
    "                \"Oencoded\":'|'.join,\n",
    "                \"Dencoded\":'|'.join,\n",
    "                \"camera_id\":','.join,\n",
    "                \"road_id\":','.join,\n",
    "                \"Olatlon\":'|'.join,\n",
    "                \"Dlatlon\":'|'.join})\n",
    "    \n",
    "    # Create dummy key for outer join\n",
    "    cameras_to_roads_gdf_grouped['key'] = 0\n",
    "    \n",
    "    print(f'Number of road requests from {cameras_to_roads_gdf.shape[0]} reduced to {cameras_to_roads_gdf_grouped.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-drama",
   "metadata": {},
   "source": [
    "# Issues\n",
    "\n",
    "Camera id 1.03608 is overlooking road ids 70712,214784,5221390839801416325_5221390839801416325 and\n",
    "road ids 214784 and 5221390839801416325_5221390839801416325 have the same start point but different endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "august-automation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check that there is not even one duplicate tuple of encoded origins and destinations - so these tuples can be used as unique ids\n",
    "try:\n",
    "    assert cameras_to_roads_gdf_grouped.duplicated(subset=['Oencoded','Dencoded']).any()==False\n",
    "except:\n",
    "    print(cameras_to_roads_gdf_grouped[cameras_to_roads_gdf_grouped.duplicated(subset=['Oencoded','Dencoded'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-karaoke",
   "metadata": {},
   "source": [
    "# Decide on timeframe and transport modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "annual-steal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide on start and end dates\n",
    "start_date = '2021-03-08'\n",
    "end_date = '2021-03-21'\n",
    "\n",
    "# Specify start and end times\n",
    "starttime = dt.time(2,0,0)\n",
    "endtime = dt.time(17,0,0)\n",
    "\n",
    "# Specify date and time detla\n",
    "date_delta = dt.timedelta(days=1)\n",
    "time_delta = dt.timedelta(hours=1)\n",
    "\n",
    "# Decide on transport modes\n",
    "modes = ['driving','bicycling','transit']\n",
    "transit_modes = ['','','bus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "opposed-sheriff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert strings to dates\n",
    "startdate = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "startdate = startdate.date()\n",
    "enddate = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "enddate = enddate.date()\n",
    "\n",
    "years = []\n",
    "months = []\n",
    "days = []\n",
    "hours_utc = []\n",
    "datetime_utc = []\n",
    "timestamp_utc = []\n",
    "# Iterate between start and end dates\n",
    "while startdate <= enddate:\n",
    "    startdatetime = datetime.combine(startdate, starttime, tzinfo=pytz.timezone('GMT'))\n",
    "    enddatetime = datetime.combine(startdate, endtime, tzinfo=pytz.timezone('GMT'))\n",
    "    # Iterate between start and end times\n",
    "    while startdatetime <= enddatetime:\n",
    "#         print(startdatetime)\n",
    "        startdatetime += time_delta\n",
    "        # Append results\n",
    "        years.append(startdatetime.year)\n",
    "        months.append(startdatetime.month)\n",
    "        days.append(startdatetime.day)\n",
    "        hours_utc.append(startdatetime.hour)\n",
    "        datetime_utc.append(startdatetime)\n",
    "        timestamp_utc.append(int(startdatetime.timestamp()))\n",
    "    startdate += date_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "urban-layer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ungrouped requests: 1566432\n",
      "Grouped requests: 163968 i.e. 89 % reduction\n"
     ]
    }
   ],
   "source": [
    "# Create transport modes dataframe\n",
    "modes_df = pd.DataFrame({'mode': modes,'transit_mode': transit_modes})\n",
    "# Create dummy key for outer join\n",
    "modes_df['key'] = 0\n",
    "\n",
    "# Create datetime dataframe\n",
    "datetime_df = pd.DataFrame({'departure_time': timestamp_utc,\n",
    "                            'departure_datetime': datetime_utc,\n",
    "                            'year':years,\n",
    "                            'month':months,\n",
    "                            'day':days,\n",
    "                            'hour':hours_utc\n",
    "                           })\n",
    "# Create dummy key for outer join\n",
    "datetime_df['key'] = 0\n",
    "\n",
    "# Outer join the two dataframes\n",
    "mode_datetime_df = datetime_df.merge(modes_df, how='outer')\n",
    "\n",
    "# Outer join last dataframe with camera_road dataframe\n",
    "road_api_requests = cameras_to_roads_gdf.merge(mode_datetime_df, how='outer')\n",
    "road_api_requests_grouped = cameras_to_roads_gdf_grouped.merge(mode_datetime_df, how='outer')\n",
    "\n",
    "# Drop dummy columns\n",
    "road_api_requests = road_api_requests.drop(columns=['key'])\n",
    "road_api_requests_grouped = road_api_requests_grouped.drop(columns=['key'])\n",
    "\n",
    "print('Ungrouped requests:',road_api_requests.shape[0])\n",
    "print('Grouped requests:',road_api_requests_grouped.shape[0],'i.e.',int(100*(road_api_requests.shape[0]-road_api_requests_grouped.shape[0])/road_api_requests.shape[0]),'% reduction')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-software",
   "metadata": {},
   "source": [
    "# Export requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "ongoing-exhibition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roads_closest_to_cameras.to_file(\"../data/output/misc/arup_roads_closest_to_cameras_london.geojson\", driver='GeoJSON', crs='EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "colored-amino",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_api_requests.head(1).to_csv('../data/output/misc/camera_road_api_requests_sample.csv',index=False)\n",
    "road_api_requests_grouped.head(1).to_csv('../data/output/misc/camera_road_api_requests_grouped_sample.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "bronze-insulin",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_api_requests.to_csv('../data/output/misc/camera_road_api_requests.csv',index=False)\n",
    "road_api_requests_grouped.to_csv('../data/output/misc/camera_road_api_requests_grouped.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptfm_kernel",
   "language": "python",
   "name": "ptfm_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
